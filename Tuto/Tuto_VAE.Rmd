---
title: "Tutoriel introductif aux autoencodeurs (variationnels)"
author: "JA and SD, StateoftheR"
date: "09/12/2021"
output:
  html_document:
    toc: true
    theme: united
---

```{r setup, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(keras)
library(ggplot2)
library(dplyr)
library(corrplot) # pour représenter la matrice des corrélations empiriques
library(factoextra) # pour avoir des représentations graphiques pour l'ACP
library(tensorflow)
if (tensorflow::tf$executing_eagerly()) {
  tensorflow::tf$compat$v1$disable_eager_execution()
}
K <- keras::backend()
```

## Introduction : l'apprentissage profond en pratique

Il existe deux grandes "bibliothèques logicielles" pour faire de l'apprentissage profond (deep learning).

1.  [Pytorch](https://pytorch.org/) est une "bibliothèque logicielle" écrite en C++, Python et C, basée sur Torch, développée par les équipes d'intelligence artificielle (IA) de Facebook, déposée en open source sur GitHub en 2017. Selon les blogs, *Pytorch* est réputé être plutôt pour les développeurs orientés recherche, plus convivial, plus facile à adapter et debugger.

2.  [TensorFlow](https://www.tensorflow.org/?hl=fr) est une plateforme Open-Source, proposant un ensemble complet et flexible d'outils, bibliothèques et ressources communautaires pour le "machine learning". C'est aussi une bibliothèque logicielle pour le calcul numérique utilisant des graphiques de flux de données. Les noeuds représentent des fonctions mathématiques et les arêtes des tableaux multidimensionnels (tenseurs) communiquant entre eux. *TensorFlow* a été développé par les équipes de Google et publié en 2015. Le "+" revendiqué est le côté écosystème complet, pas besoin de gérer CPU/GPU et facilitation de mise en production d'outils liés à l'IA.

[Keras](https://keras.io/) est une interface "high-level" pour construire et entraîner des modèles d'apprentissage profond, développée par F. Chollet et qui sert d'interface pour TensorFlow, mais aussi [The MicroSoft Cognitive ToolKit](https://docs.microsoft.com/en-us/cognitive-toolkit/) and [Theano](https://pypi.org/project/Theano/). **Keras** ne se charge pas directement des opérations de bas niveau comme les produits ou les convolutions de Tensor, et s'appuie sur un moteur *backend* (par exemple TensorFlow). **Keras** inclut aussi des ensembles de données et des modèles bien connus, pré-entraînés (sur ImageNet).

Il semble qu'aujourd'hui les deux ont travaillé sur leurs points faibles.

### Et avec R ?

Il existe des bibliothèques R de mêmes noms que celles Python, [tensorflow](https://cran.r-project.org/package=tensorflow), [keras](https://cran.r-project.org/package=keras), [torch](https://cran.r-project.org/package=torch).

1.  **torch** : construction sur PyTorch C++, pas de dépendance à Python, installation plus facile.

2.  Il existe un projet RStudio autour de TensorFlow <https://tensorflow.rstudio.com/> (et donc documentation assez complète) Pour les utilisateurs de R, **tensorflow** et **keras** sont basés sur **reticulate** et revient à utiliser des packages Python depuis R.

L'interface **Keras** a été portée sous R par JJ. Allaire, et évolue avec la philosophie "*make it R-like and natural, where possible and make it easy to port from Python, where necessary*". Vous pouvez lire l'article de blog [ci-dessous](https://blogs.rstudio.com/ai/posts/2021-11-18-keras-updates/) pour plus d'infos sur les dernières évolutions. Il existe aussi le livre Deep Learning with R écrit par F. Chollet et JJ Allaire dont une deuxième version est attendue sous peu.

"Cheatsheet" pour le package R **keras** <https://raw.githubusercontent.com/rstudio/cheatsheets/master/keras.pdf>

### Objectif du tuto

**Comprendre les commandes permettant de construire et entraîner un autoencodeur (variationnel) avec le package keras, depuis RStudio, avec un objectif de réduction de dimension**.

Quelques ateliers passés autour de l'apprentissage profond :

-   Un atelier Happy R avait déjà été proposé autour des réseaux de neurones par Sophie Donnet et Christophe Ambroise : (<https://stateofther.netlify.app/post/introduction-au-deep-learning-sous-r/>)

-   Un autre plus récent a été proposé, avec code Python (pytorch ou keras), par Charles Ollion sur l'apprentissage profond bayésien (<https://stateofther.netlify.app/post/bayesian-deep-learning/>)

## Pré-requis et installation

Pour installer **tensorflow** et **keras** et travailler depuis RStudio, suivre les consignes d'installation disponibles [ici](https://tensorflow.rstudio.com/installation/).

Sous Ubuntu, on est un peu pris par la main. Installer les packages **keras** et **tensorflow**.  
Si TensorFlow n'est pas installé sur notre machine, il suffira de lancer la fonction `tensorflow::install_tensorflow()` mais là encore, vous devriez avoir un message explicite. Si besoin on vous proposera d'installer Miniconda.


Pour vérifier son installation tensorflow :

```{r, eval = FALSE}
library(tensorflow)
tf$constant("Hellow Tensorflow")
```
Possiblement on verra apparaître des messages d'erreur qui en fait ne concernent que les calculs sur GPU. Si vous n'avez pas de carte GPU ou ne souhaitez pas faire de calculs sur GPU vous pouvez ignorer les messages. 

Si vous souhaitez pouvoir utiliser les fonctionnalités GPU, vous aurez sans doute besoin d'installation supplémentaire.

Remarque : pour avoir des infos sur sa carte graphique sous Ubuntu, taper `lspci | egrep "3D|VGA"` dans une console.

## Recette keras

Pour définir le modèle puis l'ajuster, on utilisera toujours les étapes suivantes. 


### 1.  Construction du modèle (configuration des couches)

Dans **keras** on assemble des couches pour **construire un modèle** (mode de construction le plus courant est le mode séquentiel).


`layer_input(shape = NULL)`

`layer_dense(object, units, activation = NULL, use_bias = TRUE, input_shape = NULL)`

Outre la fonction d'activation à spécifier, les schémas d'initialisation des poids (`kernel_initializer`) ou de régularisation des poids (`kernel_regularizer`) peuvent être importants.

### 2.  Processus d'apprentissage

<!-- -->

#### a.  Configuration (methode compile)

`compile(loss='mean_squared_error', optimizer='sgd')`

-   `optimizer` : optimiseur, souvent `"rmsprop"` par défaut.

-   `loss`: fonction de perte à minimiser.

-   `metrics`: métriques à évaluer pendant l'entrainement et le test du modèle.

Ex : pour de la classification

`optimizer = 'adam', loss = 'categorical_crossentropy', metrics = list('accuracy')`


#### b.  Préparer les donnees d'apprentissage

#### c.  Apprentissage (`fit`)

`fit(object, x = NULL, y = NULL, bath_size = NULL, epochs = 10)`

-   `epochs`: l'apprentissage est structuré en 'epochs', ie itération sur le jeu entier de données (ce qui fait en lots ('batches') plus petits).

-   `batch_size`: le modèle découpe les données en lots plus petits et itèrent sur chaque lote pendant l'entrainement. *Attention si le nombre total d'échantillons n'est pas divisible par la taille du lot, le dernier batch doit être le plus petit.*

### 3.  Evaluer et prédire (`predict`)


## Réduction de dimension

### Données

Nous considérerons le jeu de données "vin rouge" de la base de données de vins portugais "Vinho Verde". Nous disposons de 12 variables physico-chimiques et sensorielles, dont une variable de quality de vin correspondant à un score entre 0 et 10. Une courte description de chaque variable est disponible [ici](<https://www.datacamp.com/community/tutorials/deep-learning-python>). Les données sont utilisées à titre purement illustratif.


```{r loading-the-data}
wine <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv", sep = ";")
# Taille du jeux de données
dim(wine)
# Aperçu des premières lignes
head(wine[,-12])
# Résumé
summary(wine)
```

```{r corrplot}
wine %>%
  select_if(is.numeric) %>%
  cor() %>% # Calcul de la matrice de corrélation empirique
  corrplot::corrplot() # représentation graphique de la matrice
```

```{r scale-the-data}
scaled_data <- wine[, -12] %>%
  select_if(is.numeric) %>%
  mutate_all(.funs = scale) # On applique à toutes les colonnes la fonction scale
# La fonction scale centre et réduit un vecteur
```

#### Création de jeux de tests et d'entrainements

Ici, nous ne nous servirons pas de jeux de tests et d'entrainement. Exemple de code ci-dessous si on avait voulu en créer un pour prédire la qualité du vin. 

```{r train-and-test-datasets, echo = TRUE, eval = FALSE}
set.seed(seed = 1616)
dataset_size <- nrow(wine)
train_size <- as.integer(dataset_size * 0.85)
# Training dataset
train_dataset <- wine %>%
  group_by(quality) %>%
  sample_frac(0.85)
# Creation of the test dataset
test_dataset <- anti_join(as_tibble(wine), train_dataset)
# Scale the data
scaled_train <- train_dataset %>%
  select_if(is.numeric) %>%
  mutate_all(.funs = scale)
# Attention : il faudrait aussi mettre à l'echelle le jeu de test, peut-etre plutôt avec les valeurs du jeu d'entrainement
scaled_test <- test_dataset %>%
  select_if(is.numeric) %>%
  mutate_all(.funs = scale)
```

### Analyse en composantes principales

On fait une ACP sur toutes les données et en utilisant les variables hors qualité du vin.

```{r resultat_acp}
res.pca <- prcomp(scaled_data)
head(res.pca$x)
## plot of the eigenvalues
factoextra::fviz_eig(res.pca)
```

On peut effectuer une classification supervisée en utilisant la variable qualité pour vérifier que la qualité de prédiction ne diminue que très peu quand on passe des données complètes aux six premières composantes de l'ACP.

```{r knn-prediction, eval = FALSE}
library(class)
y <- wine$quality
neigh <- knn(scaled_data, scaled_data, cl = y, k = 3)
# confusion matrix
tab <- table(neigh, y)
# accuracy
sum(diag(tab)) / sum(rowSums(tab)) * 100
## Using the 6 first PC
neigh_reduced <- knn(res.pca$x[, 1:6], res.pca$x[, 1:6], cl = y, k = 3)
tab <- table(neigh_reduced, y)
sum(diag(tab)) / sum(rowSums(tab)) * 100
# si on voulait prédire des individus supplementaires :
# Centre-reduire les individus supplementaires
# ind.scaled  <- scale(ind.sup, center = res.pca$center, scale = res.pca$scale)
# ind.sup.coord <- predict(res.pca, newdata = ind.sup)
```

### Autoencodeur

#### 1. Définition du modèle

![Représentation schématique d'un autoencodeur](../SlidesVAE/images/Autoencoder.png)
```{r autoencodeur-1}
# Ecriture condensée
input_size <- 11
m <- 6 # nb de composantes
ae_1 <- keras_model_sequential()
ae_1 %>%
  layer_dense(units = m, input_shape = input_size, use_bias = TRUE, activation = "linear") %>%
  layer_dense(units = input_size, use_bias = TRUE, activation = "linear") %>%
  summary(ae_1)
```

On peut écrire le modèle en séparant l'encodeur et le décodeur.
```{r autoencoder-2}
# Ecriture en separant encodeur et decodeur
# Encodeur
enc_input <- layer_input(shape = input_size)
enc_output <- enc_input %>%
  layer_dense(units = m, activation = "linear")
encoder <- keras_model(enc_input, enc_output)
# Decodeur
dec_input <- layer_input(shape = m)
dec_output <- dec_input %>%
  layer_dense(units = input_size, activation = "linear")
decoder <- keras_model(dec_input, dec_output)
# Auto-encodeur
ae_2_input <- layer_input(shape = input_size)
ae_2_output <- ae_2_input %>%
  encoder() %>%
  decoder()
ae_2 <- keras_model(ae_2_input, ae_2_output)
summary(ae_2)
```
On peut récupérer la configuration du modèle à l'aide de la fonction `get_config`.

```{r get-config}
# Couche encodeur : m*n poids + m terme de biais
# Couche décodeur : m*n + n termes de biais
get_config(ae_1)
```

### 2.a Processus d'apprentissage : compilation

On compile le modèle en ajoutant fonction de perte et optimiseur

Attention des modifications de valeurs de paramètres peuvent avoir des impacts importants. Exemple du taux d'apprentissage. A ce propos, cet argument a été renommé de `lr` en `learning_rate` (pas encore à jour sur le site de RStudio)). Le Learning rate est noté $\rho$ dans nos slides de cours.


```{r ae-1-compile}
ae_1 %>% compile(
  loss = "mean_squared_error",
  optimizer = optimizer_sgd(learning_rate = 0.1) # stochastic gradient descent optimizer
)
```

### 2.b Ajustement du modèle aux données préparées

Attention : penser à standardiser les données au préalable et à les mettre sous forme de matrice et non de dataframe. Les messages d'erreur si on oublie de passer en matrice sont parfois un peu obscures.

```{r ae-1-fit}
epochs_nb <- 50L
scaled_train <- as.matrix(scaled_data)
ae_1 %>% fit(x = scaled_train, y = scaled_train, epochs = epochs_nb)
```

On peut remarques qu'il n'y a aucune contrainte sur les poids "décodeurs" et les poids "encodeurs".

```{r ae-poids}
poids <- get_weights(ae_1)
# Poids encodeurs/ decodeurs par defaut
w_encodeur <- poids[[1]] %>% print()
w_decodeur <- poids[[3]] %>% print()
```
```{r}
# ACP : unit Norm: the weights on a layer have unit norm.
sum(w_decodeur^2) / m
```

```{r ae1-predict, eval = FALSE}
ae_1predict <- ae_1 %>% predict(scaled_train)
# Repasser en non standardisé pour comparer...
varcol <- apply(wine[, -12], 2, var)
meancol <- colMeans(wine[, -12])
ae_1predict_or <- sapply(c(1:11), FUN = function(x) ae_1predict[, x] * sqrt(varcol[x]) + meancol[x])
```

## Autoencodeur variationnel

![Représentation schématique d'un autoencodeur variationnel](../SlidesVAE/images/varAutoencoderAll.png)
```{r autoencodeur-variationnel-fonctions-utiles}
# Attention ecriture keras k_rendom_normal, k_shape etc.
sampling <- function(arg) {
  z_mean <- arg[, 1:(latent_dim)]
  z_log_var <- arg[, (latent_dim + 1):(2 * latent_dim)]

  epsilon <- k_random_normal(
    shape = c(k_shape(z_mean)[[1]]),
    mean = 0.,
    stddev = epsilon_std
  )

  z_mean + k_exp(z_log_var / 2) * epsilon
}
# Fonction de perte
vae_loss <- function(x, x_decoded) {
  mse_loss <- k_sum(loss_mean_squared_error(x, x_decoded))
  kl_loss <- -0.5 * k_sum(1 + z_log_var - k_square(z_mean) - k_exp(z_log_var))
  mse_loss + kl_loss
}
```

```{r autoencodeur-variationnel}
# Parameters --------------------------------------------------------------
batch_size <- 256
latent_dim <- 12L # L spécifie que c'est un entier
epochs_nb <- 50L
epsilon_std <- 1.0

# Définition du modèle --------------------------------------------------------
x <- layer_input(shape = c(input_size))
z_mean <- layer_dense(x, latent_dim)
z_log_var <- layer_dense(x, latent_dim)

# note that "output_shape" isn't necessary with the TensorFlow backend
z <- layer_concatenate(list(z_mean, z_log_var)) %>%
  layer_lambda(sampling)

# On instancie les couches séparément pour pouvoir les réutiliser plus tard
decoder <- layer_dense(units = input_size, activation = "sigmoid")
x_decoded <- decoder(z)

# end-to-end autoencoder
vae <- keras_model(x, x_decoded)

# encoder, from inputs to latent space
encoder <- keras_model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input <- layer_input(shape = latent_dim)
x_decoded_2 <- decoder(decoder_input)
generator <- keras_model(decoder_input, x_decoded_2)

vae %>% compile(optimizer = "sgd", loss = vae_loss) # rmsprop

vae %>% fit(x = scaled_train, y = scaled_train, epochs = epochs_nb)

x_train_encoded <- predict(encoder, scaled_train, batch_size = batch_size)
## Representation dans espace latent
x_train_encoded %>%
  as_tibble() %>%
  mutate(class = as.factor(wine$quality)) %>%
  ggplot(aes(x = V1, y = V2, colour = class)) +
  geom_point()
## Representation pca
factoextra::fviz_pca_ind(res.pca, col.ind = factor(wine$quality))
```

## Bonus : pour obtenir des résultats plus cohérents entre ACP et autoencodeur linéaire monocouche

![Architectural similarity between PCA and Autoencoder from [towards data science website](https://towardsdatascience.com/build-the-right-autoencoder-tune-and-optimize-using-pca-principles-part-i-1f01f821999b)](singleAEvsPCA.png)

L'auteur du blog nous dit que souvent les autoencodeurs sont sous-optimaux et qu'ils pourraient être optimisés si on les forçait à avoir les mêmes propriétés que l'ACP à savoir :

-   Tied Weights: equal weights on Encoder and the corresponding Decoder layer.

-   Orthogonal weights: each weight vector is independent of others.

-   Uncorrelated features: output of the encoding layer are not correlated.

-   Unit Norm: the weights on a layer have unit norm.

Tout n'est pas forcément facile à faire avec **keras**. Par exemple, pour créer des poids liés, il est nécessaire de créer une sous-classe.

```{r session-info}
reticulate::py_config()
tensorflow::tf_config()
```

## Pour aller plus loin

-   Le package [tfprobability](https://rstudio.github.io/tfprobability/)

# References

Ressources autour de tensorflow, keras et rstudio : - <https://tensorflow.rstudio.com/learn/resources/> - <https://raw.githubusercontent.com/rstudio/cheatsheets/master/keras.pdf> - <https://keras.rstudio.com/articles/examples/variational_autoencoder.html>

Quelques concepts-clefs : - <https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/>

Référence du jeu de données 

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
