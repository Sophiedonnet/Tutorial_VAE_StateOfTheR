<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>A gentle introduction to the Variational Auto Encoder</title>
    <meta charset="utf-8" />
    <meta name="author" content="J. Aubert and S. Donnet for StateOfTheR" />
    <script src="slides_VAE_files/header-attrs-2.9/header-attrs.js"></script>
    <link href="slides_VAE_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="slides_VAE_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="slides_VAE_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# A gentle introduction to the Variational Auto Encoder
### J. Aubert and S. Donnet for StateOfTheR
### Dec. 2021

---





# About the auto-encoders

Auto-encoders are used for the reduction of dimension of (large) datasets. 

&lt;br&gt; 
- Let `\(X\)` be our dataset: `\(\mathbf{X}=(X_i)_{i \in 1, \dots,N_{obs}}\)`

- `\(\forall i =1,\dots,N_{obs}\)`, `\(X_i \in \mathbb{R}^n\)`.  

- Looking for two functions 

  - **Encoder** `\(e :\mathbb{R}^n \mapsto \mathbb{R}^m\)`   and  

  - **Decoder** `\(d :\mathbb{R}^m \mapsto \mathbb{R}^n\)`
  
  -  such that $$X \approx d(e(X)) \Leftrightarrow ||X -   d(e(X)) ||^2 \mbox{ small } $$ 

---

# Autoencoder 

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="images/Autoencoder.png" alt="Autoencoder scheme." width="90%" /&gt;
&lt;p class="caption"&gt;Autoencoder scheme.&lt;/p&gt;
&lt;/div&gt;


---

# About  `\(d\)` and `\(e\)` : neural networks

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="images/Autoencoder2.png" alt="Autoencoder scheme." width="90%" /&gt;
&lt;p class="caption"&gt;Autoencoder scheme.&lt;/p&gt;
&lt;/div&gt;



---

# About  `\(d\)` and `\(e\)` : neural networks

 

**One neuron** :     `\(f_j (\mathbf{x}) = \phi (&lt;w_j, \mathbf {x}&gt; + \, b_j)\)`   where

 
  - `\(\phi\)` the activation function : non linear
  
  - The quantities `\(w_j = (w_j^1, \dots, w_j^n)\)` are the weights of
    the input variables `\((x^1, \dots, x^n)\)`

  -   `\(b_j\)` is the bias of neuron `\(j\)`.


 

**At each layer `\(\ell\)`**  of the neural network: 
 

  - Receive `\(n_{\ell-1}\)`  input variables `\(\mathbf{y}^{\ell-1} =(y^{\ell-1}_{1}, \dots,y^{\ell-1}_{n_{\ell-1}})\)`
  
  - Create `\(n_\ell\)` new variables. For variable `\(j\)` of layer `\(l\)`: 
      `$$y^{\ell}_{j} = \phi(&lt;w^\ell_j, \mathbf{y}^{\ell-1}&gt;  +  b^{\ell}_j)$$` 
 

**Unknown parameters `\(\theta\)`**  
  - `\(w^\ell_j \in \mathbb{R}^{n_\ell-1}\)`, for `\(\ell =1, \dots L\)`, for `\(j=1,\dots,n_{\ell}\)`,
  - `\(b^\ell_j \in \mathbb{R}\)`, for `\(\ell =1, \dots L\)`, for `\(j=1,\dots,n_{\ell}\)`,


---

# Learning `\(d\)` and `\(e\)` 

The parameters `\(\theta = (w^\ell_j,b^\ell_j)_{j = 1\dots,n_\ell, \ell = 1,\dots,L}\)` are calibrated on a dataset `\((x_i)_{i=1, \dots , N_{obs}}\)` by minimizing the loss function

`$$\widehat{\theta} = \mbox{argmin}_{\theta \in\Theta}  \sum_{i=1}^{N_{obs}}||X_i - d_{\theta}\circ e_{\theta}(X_i)||^2$$` 

**Stochastic gradient descent**


---

# PCA versus autoencoder


- Let `\(W \in M_{n,m}(\mathbb{R})\)`, `\(W = (C_1,\dots,C_m)\)` `\(m\)` columns vectors `\(C_i\)`, `\(m &lt; n\)`. **Hyp.**:  `\((C_i)\)` are orthonormal vectors. Consequently:
  `$$W'W = I_n$$`
  
  
- Let `\(W' X_i\)` is the projector of vector `\(X_i\)` on the sub-vectorial space generated by the columns of `\(W\)`. 
  
-  We are looking for  `\(W\)` minimizing the inertia of the projected dataset: 
$$
`\begin{aligned}
W^* &amp;=\mbox{argmax}_{\{W \in M_{n,m}(\mathbb{R}), W'W = I_n\}} \sum_{i=1}^{N_{obs}} || W'X_i||^2\\ &amp;=\mbox{argmin}_{\{W \in M_{n,m}(\mathbb{R}), W'W = I_n\}} \sum_{i=1}^{N_{obs}} || X_i - WW'X_i||^2
\end{aligned}`
$$

---

# PCA versus autoencoder

- `\(W' = e\)`  **linear** encoder function

- `\(W = d\)` : **linear** decoder function

- Note that if you use neural networks with linear activation function and one layer, you will get `\(W\)` not necessarily orthogonal. 


[Lien vers une démonstration propre](http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_ml/rn/rn_9_auto.html)


---

# Using the autoencoder to simulate  



&lt;img src="images/VarAutoencoder.png" width="70%" style="display: block; margin: auto;" /&gt;


  -   The optimization of the autoencoder supplies `\((Z_1, \dots, Z_{N_{obs}}) = (e(x_1), \dots, e(X_{N_{obs}}))\)`
  
  - **How can we simulate the `\(z's\)` such that `\(d(z)\)` looks like my original data?**  

  -  How to construct a "machine" able to generate coherent other `\(Z_i\)`.   
  
  - Need to  constrain/ structure the latent space. 
  
---

# Probabilistic version of the autoencoder
  
  -  **Idea** : put a prior distribution on the latent space et estimate the posterior distribution.  


  - **A statistical model with latent variables**
  
  `$$X_i =d(Z_i) + \epsilon_i$$`
  `$$Z_i \sim_{i.i.d.}N_m(0,I_m)$$`
  `$$\epsilon_i \sim_{i.i.d.} \mathcal{N}_n(0,c I_n)$$`
 
  
  - Likelihood 
   `$$\ell(\mathbf{X}; d)  =  \int_{\mathbf{Z}} p(\mathbf{X} | \mathbf{Z};d)p(\mathbf{Z})d\mathbf{Z}$$`
  
  **Not explicit**
  
  - EM requires the posterior distribution of `\(\mathbf{Z}\)`

  $$p(\mathbf{Z} | \mathbf{X}; d) \propto p(\mathbf{X}|\mathbf{Z}; d)p(\mathbf{Z}) $$
  **Very complex  too**



---

# Approximate the posterior distribution


 - Since  `\(\ell(\mathbf{X}; d)\)`  is too difficult to tackle because of the form of `\(p(\mathbf{Z} | \mathbf{X}; d)\)`

 - Let's   simplify that distribution 
  `$$p(\mathbf{Z}  | \mathbf{X};d) = \prod_{i=1}^{N} p(Z_i |  X_i; d)  \approx q_{\mathbf{X}}(\mathbf{Z};g,H)  = \prod_{i=1}^{N} q_{ X_i}(Z_i;g,H)$$`
  `$$q_{X_i}(Z_i;g,h) =\mathcal{N}_m(g(X_i),H(X_i))$$`


- Replace the likelihood by the ELBO 

 $$
`\begin{eqnarray}
 ELBO(d,g,H) &amp;=&amp;\ell(\mathbf{X}; d)-  KL(q(\mathbf{Z};\mathbf{X},g,H), p\mathbf{Z} |\mathbf{X};d))\\
 &amp;=&amp;\mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z}; ,g,H)}[\log p(\mathbf{X} , \mathbf{Z};d)] + Entr(q_{\mathbf{X}}(\mathbf{Z};g,H)))\\
 &amp;=&amp; \mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,H)}[\log p(\mathbf{X} | \mathbf{Z};d)]- KL(q_{\mathbf{X}}(\mathbf{Z};g,H), p(\mathbf{Z}))\\
\end{eqnarray}`
 $$
 
 
 
---
# Maximize  a variational lower bound
   `$$(\hat{d},\hat{g},\hat{H}) = \mbox{argmin}_{d,g,H} ELBO(d,H,g)$$` 

 `$$ELBO(d,g,H)  = \mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,H)}[\log p(\mathbf{X} | \mathbf{Z};d)]- KL(q_{\mathbf{X}}(\mathbf{Z};g,h), p(\mathbf{Z}))$$`
 
 - **Reconstruction term**
 
`$$\mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,H)}[\log p(\mathbf{X} | \mathbf{Z};d)] = \mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,H)}  \left[\sum_{i=1}^N - \frac{||X_i - f(Z_i)||^2}{2c}\right]$$` 


 - **Regularisation term** :  `\(KL\)`
 
- `\(c\)` : variance parameter which balances regularisation and  reconstruction


---

#About d

`\(d\)` neural network function as before

---

#About g and h

 - Are called the "encoder part"
 - `\(g\)` and `\(H\)`: 
 - `\(H(X)\)` is a covariance so 
    - it should be a square symetric matrix 
    - **Simplification** : diagonal matrix `\(H(X) = h'(X)h(X)\)`
    - `\(h(X) \in \mathbb{R}^m\)`
  - `\(h(X) = h_2(h_1(X))\)`, `\(g(X) = g_2(g_1(X))\)`, `\(g_1 = h_1\)`
  
  
&lt;img src="images/approxZ.png" width="90%" style="display: block; margin: auto;" /&gt;


    
---
#Evaluation of the expectation

Note that the term 
    `\(\mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,h)}  \left[\sum_{i=1}^N - \frac{||X_i - f(Z_i)||^2}{2c}\right]\)`
can not be evaluated. 

So people simulate latent variable

`$$\mathbb{E}_{q_{\mathbf{X}}(\mathbf{Z};g,h)}  \left[\sum_{i=1}^N - \frac{||X_i - f(Z_i)||^2}{2c}\right] \approx  \left[\sum_{i=1}^N - \frac{||X_i - f(g(X_i) + diag(h(X_i))\xi_i)||^2}{2c}\right]$$`
where `\(\xi_i\sim \mathcal{N}_m(0,\mathbb{I}_m)\)`  
    


   
   
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
